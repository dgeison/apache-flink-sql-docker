# Trabalho PrÃ¡tico: Apache Flink - InstalaÃ§Ã£o e PrÃ¡tica

**DIRETORIA DE EDUCAÃ‡ÃƒO CONTINUADA - IEC**

---

## ğŸ“‹ InformaÃ§Ãµes da Disciplina

| Campo | InformaÃ§Ã£o |
|-------|------------|
| **Disciplina** | Camadas e ServiÃ§os de Consumo de Dados |
| **Curso** | Arquitetura e Engenharia de Dados |
| **Professor** | Ricardo Brito Alves |
| **InstituiÃ§Ã£o** | PUC Minas |

### ğŸ‘¥ Equipe
- **Aluno**: [Dgeison SerrÃ£o Peixoto]

---

## ğŸ¯ Apache Flink e SQL

### Objetivos do Trabalho

O **Apache Flink** Ã© uma estrutura de cÃ³digo aberto para processamento de dados nos modos:
- **Stream** (fluxo de dados em tempo real)
- **Batch** (processamento em lote)

#### ğŸ”§ Tecnologias Suportadas
- **Plataformas**: Apache Kafka, bancos JDBC
- **Linguagens**: Java, Scala, Python (PyFlink)
- **IntegraÃ§Ã£o ML**: Bibliotecas de Machine Learning via PyFlink

#### ğŸ’¡ Por que SQL?
O **SQL** Ã© uma das linguagens mais universais no mundo dos dados:
- **Analistas de dados** â†’ Consultas e relatÃ³rios
- **Cientistas de dados** â†’ AnÃ¡lise exploratÃ³ria  
- **Engenheiros de dados** â†’ Pipelines de ETL
- **AbstraÃ§Ã£o universal** â†’ Independente da tecnologia subjacente

### ğŸš€ Proposta do Projeto
Com o Apache Flink, vocÃª pode definir **pipelines de dados inteiros** em SQL puro usando o **SQL Client**. Este trabalho configura uma plataforma local baseada em Docker para Apache Flink, incluindo um cliente SQL interativo.

> **Fonte**: Trabalho adaptado de [Apache Flink on Docker](https://dev.to/ftisiot/apache-flink-on-docker-4kij)

---

## ğŸ› ï¸ Atividades PrÃ¡ticas

### 1. ConfiguraÃ§Ã£o do Apache Flink com Docker Compose

O Apache Flink Ã© uma tecnologia poderosa que merece ser explorada. Para minimizar o esforÃ§o de configuraÃ§Ã£o, utilizamos **Docker** como soluÃ§Ã£o containerizada portÃ¡vel.

#### ğŸ“‹ PrÃ©-requisitos
Certifique-se de que estÃ£o instalados:
- âœ… Docker Desktop
- âœ… Docker Compose

#### ğŸš€ Iniciando o Ambiente

```bash
# Navegue atÃ© o diretÃ³rio do projeto
cd flink-sql-cli-docker

# Inicie os serviÃ§os em background
docker-compose up -d
```

Este comando iniciarÃ¡ **3 componentes** do Apache Flink:
- **Job Manager** â†’ Coordenador do cluster
- **Task Manager** â†’ Executor de tarefas
- **SQL Client** â†’ Interface SQL interativa

#### âœ… VerificaÃ§Ã£o do Status

```bash
# Verifique se os contÃªineres estÃ£o rodando
docker-compose ps
```

**Resultado esperado:**
```
    Name                 Command            State                    Ports                  
------------------------------------------------------------------------------------------
jobmanager      /docker-entrypoint.sh   Up      6123/tcp, 0.0.0.0:8081->8081/tcp        
sql-client      /docker-entrypoint.sh   Up                                               
taskmanager     /docker-entrypoint.sh   Up      6121-6125/tcp                            
```

#### ğŸŒ Interface Web
A **interface web do Flink** estÃ¡ disponÃ­vel em: **http://localhost:8081**

Esta ferramenta permite:
- Monitorar status do cluster
- Visualizar jobs em execuÃ§Ã£o
- Acompanhar mÃ©tricas de performance
- Gerenciar pipelines de dados

---

### 2. ConfiguraÃ§Ãµes do Docker Compose

#### ğŸ“ Mapeamento de Volumes

No `docker-compose.yml`, sÃ£o mapeadas duas pastas importantes:

**`/settings`**
- Compartilha configuraÃ§Ãµes entre host e containers
- Ãštil para arquivos de autenticaÃ§Ã£o (keystores, certificados)
- Permite customizaÃ§Ã£o sem rebuild da imagem

**`/data`**  
- Disponibiliza dados para processamento
- ContÃ©m o arquivo `test.csv` para demonstraÃ§Ãµes
- Facilita testes com arquivos do sistema local

---

### 3. Utilizando o SQL Client

#### ğŸ”‘ Acessando o Cliente SQL

```bash
# Entre no container SQL Client
docker exec -it sql-client /bin/bash

# Inicie o cliente SQL do Flink
./sql-client.sh
```

Agora vocÃª terÃ¡ um **cliente SQL totalmente funcional** para criar pipelines de dados com vÃ¡rias fontes e destinos.

#### ğŸ“Š Exemplo PrÃ¡tico: Criando uma Tabela

Execute o comando para criar uma tabela baseada no arquivo CSV:

```sql
CREATE TABLE people_job (
    id INT,
    name STRING,
    job STRING,
    salary BIGINT
) WITH (
    'connector' = 'filesystem',
    'path' = 'file:///data/test.csv',
    'format' = 'csv',
    'csv.ignore-parse-errors' = 'true'
);
```

#### ğŸ” Consultando os Dados

```sql
-- Listar todos os registros
SELECT * FROM people_job;
```

**Resultado esperado:**
```
+------+----------+------------------------+--------+
|   id |     name |                    job | salary |
+------+----------+------------------------+--------+
|    1 |      Ugo |        Football Player | 200000 |
|    2 |    Carlo | Crocodile domesticator |  30000 |
|    3 |    Maria |      Software Engineer | 210000 |
|    4 |   Sandro |            UX Designer |  70000 |
|    5 |  Melissa |      Software Engineer |  95000 |
+------+----------+------------------------+--------+
```

#### ğŸ“ˆ Consultas AvanÃ§adas

```sql
-- Buscar por ID especÃ­fico
SELECT * FROM people_job WHERE id = 1;

-- Filtrar por profissÃ£o
SELECT job FROM people_job WHERE id = 2;

-- AnÃ¡lise estatÃ­stica por profissÃ£o
SELECT 
    job,
    COUNT(*) as total_pessoas,
    AVG(salary) as salario_medio,
    MAX(salary) as maior_salario
FROM people_job 
GROUP BY job;
```

#### ğŸšª Saindo do Cliente SQL

Para sair da visualizaÃ§Ã£o de resultados:
```
Pressione: Q
```

Para sair do SQL Client:
```sql
EXIT;
```

Para sair do container:
```bash
exit
```

---

## ğŸ“‹ Entrega do Trabalho

### ğŸ¯ Requisitos de Entrega

1. **Screenshot do Dashboard**
   - Acesse: http://localhost:8081/
   - Capture a interface web do Apache Flink Dashboard
   - Certifique-se de que mostra o cluster ativo

2. **EvidÃªncias de ExecuÃ§Ã£o**
   - Comandos executados no SQL Client
   - Resultados das consultas SQL
   - Status dos containers Docker

3. **DocumentaÃ§Ã£o**
   - RelatÃ³rio das atividades realizadas
   - AnÃ¡lise dos resultados obtidos
   - ReflexÃµes sobre o uso do Apache Flink

### âœ… CritÃ©rios de AvaliaÃ§Ã£o

- **ConfiguraÃ§Ã£o correta** do ambiente Docker
- **ExecuÃ§Ã£o bem-sucedida** dos comandos SQL
- **Captura adequada** do dashboard web
- **DocumentaÃ§Ã£o clara** do processo
- **CompreensÃ£o demonstrada** dos conceitos

---

## ğŸ“ Aprendizados Esperados

Ao concluir este trabalho, vocÃª terÃ¡:

- âœ… **Configurado um cluster Apache Flink** completo
- âœ… **Executado consultas SQL** em dados distribuÃ­dos  
- âœ… **Compreendido arquiteturas** de processamento de streams
- âœ… **Trabalhado com containerizaÃ§Ã£o** via Docker
- âœ… **Explorado ferramentas** de Big Data modernas

### ğŸš€ PrÃ³ximos Passos

- IntegraÃ§Ã£o com Apache Kafka para streams reais
- Conectores para bancos de dados relacionais
- Desenvolvimento de jobs Java/Scala personalizados
- ImplementaÃ§Ã£o de pipelines de Machine Learning
- Deploy em clusters de produÃ§Ã£o

---

**ğŸ“š Material Complementar**: [DocumentaÃ§Ã£o Oficial Apache Flink](https://flink.apache.org/docs/)

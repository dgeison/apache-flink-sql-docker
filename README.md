# Apache Flink SQL Client - Ambiente Docker

Este projeto configura um ambiente completo do Apache Flink com SQL Client usando Docker Compose, desenvolvido para fins educacionais na disciplina **Camadas e ServiÃ§os de Consumo de Dados** do curso de **Arquitetura e Engenharia de Dados** da PUC Minas.

## ğŸ“‹ Sobre o Projeto

O Apache Flink Ã© uma plataforma de cÃ³digo aberto para processamento de dados em tempo real (streaming) e em lote (batch). Este ambiente permite:

- **Processamento de Stream e Batch**: Analise dados em tempo real ou processos em lote
- **SQL Nativo**: Use SQL puro para criar pipelines de dados complexos
- **Conectores MÃºltiplos**: Suporte a Kafka, JDBC, Elasticsearch e outros
- **Interface Web**: Dashboard completo para monitoramento
- **Ambiente Isolado**: ConfiguraÃ§Ã£o completa via Docker

### ğŸ¯ Objetivos de Aprendizado

- Compreender os conceitos de processamento de dados distribuÃ­do
- Praticar SQL para pipelines de dados em tempo real
- Trabalhar com tecnologias de Big Data e streaming
- Entender arquiteturas de dados modernas

## ğŸ—ï¸ Arquitetura do Sistema

O ambiente Ã© composto por 3 contÃªineres Docker:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SQL Client    â”‚    â”‚   Job Manager   â”‚    â”‚  Task Manager   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ Interface SQL   â”‚â—„â”€â”€â–ºâ”‚ Coordenador     â”‚â—„â”€â”€â–ºâ”‚ Executor de     â”‚
â”‚ para Flink      â”‚    â”‚ do Cluster      â”‚    â”‚ Tarefas         â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Dados CSV     â”‚
                    â”‚   /data/        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes:

- **Job Manager**: Coordena o cluster Flink e gerencia os jobs
- **Task Manager**: Executa as tarefas de processamento de dados
- **SQL Client**: Interface interativa para executar comandos SQL
- **Web UI**: Dashboard web disponÃ­vel em `http://localhost:8081`

## ğŸš€ Como Usar

### PrÃ©-requisitos

- Docker Desktop instalado
- Docker Compose disponÃ­vel
- Pelo menos 4GB de RAM livres

### 1. Iniciando o Ambiente

```bash
# Navegue atÃ© o diretÃ³rio do projeto
cd flink-sql-cli-docker

# Inicie todos os serviÃ§os em background
docker-compose up -d

# Verifique se os contÃªineres estÃ£o rodando
docker-compose ps
```

**SaÃ­da esperada:**
```
    Name                 Command            State                    Ports                  
------------------------------------------------------------------------------------------
jobmanager      /docker-entrypoint.sh   Up      6123/tcp, 0.0.0.0:8081->8081/tcp        
sql-client      /docker-entrypoint.sh   Up                                               
taskmanager     /docker-entrypoint.sh   Up      6121-6125/tcp                            
```

### 2. Acessando o SQL Client

```bash
# Entre no contÃªiner SQL Client
docker exec -it sql-client /bin/bash

# Inicie o cliente SQL do Flink
./sql-client.sh
```

### 3. Experimentando com SQL

#### Criando uma Tabela de Exemplo

```sql
CREATE TABLE people_job (
    id INT,
    name STRING,
    job STRING,
    salary BIGINT
) WITH (
    'connector' = 'filesystem',
    'path' = 'file:///data/test.csv',
    'format' = 'csv',
    'csv.ignore-parse-errors' = 'true'
);
```

#### Consultas de Exemplo

```sql
-- Listar todos os registros
SELECT * FROM people_job;

-- Buscar por ID especÃ­fico
SELECT * FROM people_job WHERE id = 1;

-- Filtrar por profissÃ£o
SELECT name, salary FROM people_job WHERE job = 'Software Engineer';

-- Calcular estatÃ­sticas
SELECT 
    job,
    COUNT(*) as total_pessoas,
    AVG(salary) as salario_medio,
    MAX(salary) as maior_salario
FROM people_job 
GROUP BY job;
```

### 4. NavegaÃ§Ã£o no Terminal

#### Comandos Ãšteis no SQL Client:

```bash
# Listar todas as tabelas
SHOW TABLES;

# Descrever uma tabela
DESCRIBE people_job;

# Sair da visualizaÃ§Ã£o de resultados de uma query
# Pressione 'Q'

# Sair do SQL Client (vÃ¡rias opÃ§Ãµes)
EXIT;
# ou
QUIT;
# ou pressione Ctrl + C

# Sair do contÃªiner Docker
exit
```

#### SequÃªncia para Sair Completamente:

```bash
# 1. Se estiver visualizando resultados, pressione:
Q

# 2. Sair do Flink SQL Client:
Flink SQL> EXIT;

# 3. Sair do container Docker:
bash-4.4$ exit

# Agora vocÃª estÃ¡ de volta ao seu terminal do Windows
```

#### Comandos Docker Ãšteis:

```bash
# Ver logs dos serviÃ§os
docker-compose logs

# Ver logs de um serviÃ§o especÃ­fico
docker-compose logs jobmanager

# Parar todos os serviÃ§os
docker-compose down

# Reiniciar um serviÃ§o especÃ­fico
docker-compose restart taskmanager

# Ver uso de recursos
docker stats
```

## ğŸŒ Interface Web

Acesse o Dashboard do Flink em: **http://localhost:8081**

### Funcionalidades do Dashboard:

- **Overview**: Status geral do cluster
- **Jobs**: Jobs em execuÃ§Ã£o e histÃ³rico
- **Task Managers**: Status dos executores
- **Job Manager**: InformaÃ§Ãµes do coordenador
- **Submit New Job**: Upload de jobs JAR

## ğŸ“ Estrutura do Projeto

```
flink-sql-cli-docker/
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o dos contÃªineres
â”œâ”€â”€ README.md                   # Este arquivo
â”œâ”€â”€ .gitignore                  # Arquivos ignorados pelo Git
â”œâ”€â”€ texto explicativo.md        # DocumentaÃ§Ã£o original da disciplina
â”œâ”€â”€ data/
â”‚   â””â”€â”€ test.csv               # Dados de exemplo para testes
â”œâ”€â”€ settings/                  # ConfiguraÃ§Ãµes compartilhadas
â””â”€â”€ sql-client/
    â”œâ”€â”€ Dockerfile             # Imagem customizada do SQL Client
    â”œâ”€â”€ docker-entrypoint.sh   # Script de inicializaÃ§Ã£o
    â”œâ”€â”€ bin/
    â”‚   â””â”€â”€ sql-client.sh      # Script do cliente SQL
    â””â”€â”€ conf/
        â””â”€â”€ flink-conf.yaml    # ConfiguraÃ§Ãµes do Flink
```

## ğŸ”§ Conectores IncluÃ­dos

O ambiente vem prÃ©-configurado com conectores para:

- **Kafka**: Processamento de streams
- **JDBC**: Bancos de dados relacionais
- **Elasticsearch**: Busca e analytics
- **PostgreSQL**: Banco de dados especÃ­fico
- **JSON/Avro**: Formatos de dados
- **Filesystem**: Arquivos locais (CSV, JSON, etc.)

## ğŸ’¡ Casos de Uso PrÃ¡ticos

### 1. Processamento de Logs em Tempo Real
```sql
-- Exemplo conceitual para logs de web server
CREATE TABLE web_logs (
    timestamp_log TIMESTAMP,
    ip_address STRING,
    method STRING,
    url STRING,
    status_code INT,
    response_size BIGINT
) WITH (
    'connector' = 'kafka',
    'topic' = 'web-logs',
    'properties.bootstrap.servers' = 'localhost:9092',
    'format' = 'json'
);
```

### 2. ETL de Dados
```sql
-- TransformaÃ§Ã£o e agregaÃ§Ã£o de dados
CREATE TABLE sales_summary AS
SELECT 
    DATE_FORMAT(order_date, 'yyyy-MM') as month,
    product_category,
    SUM(amount) as total_sales,
    COUNT(*) as total_orders
FROM sales_raw
GROUP BY DATE_FORMAT(order_date, 'yyyy-MM'), product_category;
```

## ğŸ› Troubleshooting

### Problemas Comuns:

1. **Porta 8081 jÃ¡ em uso**
   ```bash
   # Verificar processo usando a porta
   netstat -tulpn | grep 8081
   # Ou mudar a porta no docker-compose.yml
   ```

2. **ContÃªineres nÃ£o iniciam**
   ```bash
   # Verificar logs
   docker-compose logs
   # Limpar volumes
   docker-compose down -v
   ```

3. **Sem memÃ³ria suficiente**
   ```bash
   # Verificar uso de recursos
   docker stats
   # Aumentar memÃ³ria do Docker Desktop
   ```

4. **SQL Client nÃ£o conecta**
   ```bash
   # Verificar se o Job Manager estÃ¡ ativo
   docker-compose ps
   # Reiniciar o SQL Client
   docker-compose restart sql-client
   ```

## ğŸ“š PrÃ³ximos Passos

1. **IntegraÃ§Ã£o com Kafka**: Configure um broker Kafka para streams reais
2. **Conectores de Banco**: Conecte com PostgreSQL ou MySQL
3. **Jobs Complexos**: Desenvolva jobs Java/Scala para o Flink
4. **Monitoramento**: Configure mÃ©tricas e alertas
5. **ProduÃ§Ã£o**: Estude clusters Flink em produÃ§Ã£o

## ğŸ“ Material de Estudo

- [DocumentaÃ§Ã£o Oficial Apache Flink](https://flink.apache.org/docs/)
- [Flink SQL Cookbook](https://flink.apache.org/2020/07/28/flink-sql-cookbook.html)
- [Tutoriais de Streaming](https://flink.apache.org/tutorials/)

## ğŸ“ LicenÃ§a

Este projeto Ã© baseado no Apache Flink e mantÃ©m a licenÃ§a Apache 2.0.

---

**Desenvolvido para fins educacionais - PUC Minas**  
**Disciplina**: Camadas e ServiÃ§os de Consumo de Dados  
**Curso**: Arquitetura e Engenharia de Dados